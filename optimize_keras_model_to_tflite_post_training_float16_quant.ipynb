{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of post_training-float16-quant.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steveseguin/facetracker/blob/master/optimize_keras_model_to_tflite_post_training_float16_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gyqAw1M9lyab",
        "colab": {}
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install -U tf-nightly\n",
        "#! pip install -U tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WsN6s5L1ieNl",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "#import tensorflowjs as tfjs\n",
        "import tensorflow as tf\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "00U0taBoe-w7",
        "colab": {}
      },
      "source": [
        "! git clone --depth 1 https://github.com/steveseguin/facetracker.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6nb7OPlXs_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.lite.constants.FLOAT16\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_i8B2nDZmAgQ",
        "colab": {}
      },
      "source": [
        "!ls -lh {\"./facetracker/\"}\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "#model = load_model('./facetracker/full.h5', compile=False)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(\"./facetracker/full.h5\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.lite.constants.FLOAT16]\n",
        "tflite_model = converter.convert()\n",
        "open(\"./facetracker/face_model.tflite\", \"wb\").write(tflite_model)\n",
        "!ls -lh {\"./facetracker/\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ie9pQaQrn5ue",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"./facetracker/face_model.tflite\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5l6-ciItvX6"
      },
      "source": [
        "Run the TensorFlow Lite model using the Python TensorFlow Lite Interpreter. \n",
        "\n",
        "### Load the test data\n",
        "\n",
        "First, let's load the MNIST test data to feed to the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTIuU07NuKFL",
        "colab": {}
      },
      "source": [
        "_, mnist_test = tf.keras.datasets.mnist.load_data()\n",
        "images, labels = tf.cast(mnist_test[0], tf.float32)/255.0, mnist_test[1]\n",
        "\n",
        "mnist_ds = tf.data.Dataset.from_tensor_slices((images, labels)).batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ap_jE7QRvhPf"
      },
      "source": [
        "### Load the model into the interpreters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jn16Rc23zTss",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J8Pztk1mvNVL",
        "colab": {}
      },
      "source": [
        "interpreter_fp16 = tf.lite.Interpreter(model_path=str(tflite_model_fp16_file))\n",
        "interpreter_fp16.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2opUt_JTdyEu"
      },
      "source": [
        "### Test the models on one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKslvo2kwWac",
        "colab": {}
      },
      "source": [
        "for img, label in mnist_ds:\n",
        "  break\n",
        "\n",
        "interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], img)\n",
        "interpreter.invoke()\n",
        "predictions = interpreter.get_tensor(\n",
        "    interpreter.get_output_details()[0][\"index\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZClM2vo3_bm",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "plt.imshow(img[0])\n",
        "template = \"True:{true}, predicted:{predict}\"\n",
        "_ = plt.title(template.format(true= str(label[0].numpy()),\n",
        "                              predict=str(predictions[0])))\n",
        "plt.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3gwhv4lKbYZ4",
        "colab": {}
      },
      "source": [
        "interpreter_fp16.set_tensor(\n",
        "    interpreter_fp16.get_input_details()[0][\"index\"], img)\n",
        "interpreter_fp16.invoke()\n",
        "predictions = interpreter_fp16.get_tensor(\n",
        "    interpreter_fp16.get_output_details()[0][\"index\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CIH7G_MwbY2x",
        "colab": {}
      },
      "source": [
        "plt.imshow(img[0])\n",
        "template = \"True:{true}, predicted:{predict}\"\n",
        "_ = plt.title(template.format(true= str(label[0].numpy()),\n",
        "                              predict=str(predictions[0])))\n",
        "plt.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LwN7uIdCd8Gw"
      },
      "source": [
        "### Evaluate the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "05aeAuWjvjPx",
        "colab": {}
      },
      "source": [
        "def eval_model(interpreter, mnist_ds):\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "  for img, label in mnist_ds:\n",
        "    total_seen += 1\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(output_index)\n",
        "    if predictions == label.numpy():\n",
        "      num_correct += 1\n",
        "\n",
        "    if total_seen % 500 == 0:\n",
        "      print(\"Accuracy after %i images: %f\" %\n",
        "            (total_seen, float(num_correct) / float(total_seen)))\n",
        "\n",
        "  return float(num_correct) / float(total_seen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5mWkSbMcU5z",
        "colab": {}
      },
      "source": [
        "# Create smaller dataset for demonstration purposes\n",
        "mnist_ds_demo = mnist_ds.take(2000)\n",
        "\n",
        "print(eval_model(interpreter, mnist_ds_demo))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Km3cY9ry8ZlG"
      },
      "source": [
        "Repeat the evaluation on the float16 quantized model to obtain:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-9cnwiPp6EGm",
        "colab": {}
      },
      "source": [
        "# NOTE: Colab runs on server CPUs. At the time of writing this, TensorFlow Lite\n",
        "# doesn't have super optimized server CPU kernels. For this reason this may be\n",
        "# slower than the above float interpreter. But for mobile CPUs, considerable\n",
        "# speedup can be observed.\n",
        "print(eval_model(interpreter_fp16, mnist_ds_demo))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7lfxkor8pgv"
      },
      "source": [
        "In this example, you have quantized a model to float16 with no difference in the accuracy.\n",
        "\n",
        "It's also possible to evaluate the fp16 quantized model on the GPU. To perform all arithmetic with the reduced precision values, be sure to create the `TfLiteGPUDelegateOptions` struct in your app and set `precision_loss_allowed` to `1`, like this:\n",
        "\n",
        "```\n",
        "//Prepare GPU delegate.\n",
        "const TfLiteGpuDelegateOptions options = {\n",
        "  .metadata = NULL,\n",
        "  .compile_options = {\n",
        "    .precision_loss_allowed = 1,  // FP16\n",
        "    .preferred_gl_object_type = TFLITE_GL_OBJECT_TYPE_FASTEST,\n",
        "    .dynamic_batch_enabled = 0,   // Not fully functional yet\n",
        "  },\n",
        "};\n",
        "```\n",
        "\n",
        "Detailed documentation on the TFLite GPU delegate and how to use it in your application can be found [here](https://www.tensorflow.org/lite/performance/gpu_advanced?source=post_page---------------------------)"
      ]
    }
  ]
}